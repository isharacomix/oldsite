---
layout: post
title: Running a Reading Group
tags: blog
---

![Photo]({{ site.baseurl }}img/event_reading_group.jpg)

Last Friday, we held the first meeting of the <strong>Fundamentals in Teaching Research Reading Group</strong>, an interdisciplinary group of Graduate students who get together to discuss current literature as it relates to teaching and learning. During the semester, we will be meeting three times, each time with a focus on a paper related to assessment - this time, we looked at peer assessment, motivated by <a href="http://www.utsc.utoronto.ca/~psya01/peerScholar/peerScholar%20paper%20-%20Pare%20and%20Joordens%20(2008).pdf">Pare and Joorden's paper</a><sup>1</sup> on PeerScholar, a tool for facilitating peer review.

Peer review is an interesting proposition for two reasons. The first being that feedback is among the most important parts of education, and when feedback is not timely or detailed, it loses its effect. Because teachers are often outnumbered 40 to 1, the time it takes for a teacher to evaluate his or her students often delays feedback for a week or more after the submission, and when rushed, the feedback is often superficial. This not only limits the number of assignments that can be assigned, but also the number of drafts that students can submit. By crowdsourcing the grading to the students, each student only evaluates three of their peers, meaning that each student receives three evaluations, done more quickly, more thoroughly, and from more viewpoints than the teacher alone can provide.

Besides the logistical benefit, there is also pedagogical value in peer-review. By introducing the students to the tasks of reviewing, they approach the assignment from a different perspective, seeing how the assignment matches up to the learning objectives of the course. Coursework serves the purpose of allowing a student to demonstrate their learning to the instructor, and rubrics provide the measuring stick that the instructor intends to use so that students can see how the assignment relates to the learning objectives and why it is important. By seeing how one's peers approached the problem and how the instructor intends to measure it, the student - in theory - has the opportunity to look at the assignment beyond how it appears on the surface.

Among the many challenges to peer review is one where instructors are concerned as to whether peers can assess one another fairly enough for their assessments to count as formal grades, which is the issue that this paper sought to address. Through their study, the authors found that, while not perfect, the assessments of peer reviewers lines up rather closely to the assessments of teaching assistants and teachers. Therefore, if a teacher's grade is the gold standard, students do a well enough job of assessment for at least low-stakes assignments for peer review to be a reasonable option.

As the paper was mostly in favor of peer review, our group challenged other assumptions that the paper made regarding deploying peer review in their own disciplines. One such concern was student buy-in: as overworked as students already are, why add grading each others' work to their plates? Students would easily come to resent their instructors if they were of the impression that they were participating in peer grading simply to alleviate their instructor's stress. While there is ostensibly some "learning value" to be had from the act of peer evaluation, if students shrug their shoulders and don't buy in, then it's going to result in superficial peer reviews that won't end up doing anybody any good at all. 

Another issue was fatigue. The first time students peer review each other, they take it seriously. While one would assume that they would get better and more accurate with each peer review across a term, experience in our classes has shown that as it becomes a chore, students take it less seriously, giving less feedback and higher grades as the semester marches on. Peer-grading, like many other "active learning" activities, is very mentally taxing. It tires students out more than other techniques, meaning that it has to be used strategically in order to avoid wearing it out.

Yet another issue is that "peer grading hurts those that it stands to help the most", which is to say that the students who really need the peer review are the ones who are going to be struggling the most with it. If students don't grasp the concepts well, then their feedback will be completely unhelpful, and they'll be free riders in the peer reviewing climate. In other words, peer review basically becomes a public service for the best students in the class, which while not necessarily a bad thing (if you are of the persuasion that everyone, even the strongest students, should leave a class with something more than they came in... which is another blog entry entirely) it gets in the way of the supposed pedagogical benefits, which breaks the intentionality of the whole thing.

All of these issues were great points, and I commend the group on their excellent criticism of the paper. Part of what made the reading group so wonderful was the casual atmosphere that surrounded our discussion. Part of what I loved about THATCamp was how none of the "talks" that we attended were a single person talking at us, but rather, a group discussion focused on a single topic. I tried and succeeded at emulating that atmosphere during this discussion, and it was a very productive and enjoyable hour. I was afraid that the discussion would be very forced and contrived, but the way it grew organically either speaks very highly of my leadership or (more likely) the kind of people who would be attracted to such a discussion in the first place. I'm looking forward to the next two meetings in the hope that we can make them as successful as the first.

*<sub><strong>1</strong>: Pare, D. E., &amp; Joordens, S. (2008). Peering into large lectures: Examining peer and expert mark agreement using peerScholar, an online peer-assessment tool. <strong>Journal of Computer Assisted Learning</strong>, 24(6), 526â€“540.</sub>*
