---
layout: post
title: Putting it All Together
---

Today I got to attend a great talk by Dr. David Wright, a three-time graduate of the NC State Computer Science Department, which was unfortunately cut short due to a time conflict. He was discussing a problem that I was recently thinking about, which is the lack of cohesion in the Undergraduate Computer Science curriculum.

In my University, we have three common courses that form the early component of a Computer Science student's career, CSC 116 - Introduction to Computing, CSC 216 - Programming Concepts, and CSC 316 - Data Structures. These courses were colloquially referred to by Undergraduates including myself as Java I, Java II, and Java III, respectively. We knew that these classes existed to give us a basic grounding in elementary programming concepts, and since I had been one of the advanced students who had been programming since high school, few of the concepts were particularly new to me. However, upon entering my Java III class, my professor (who I then went on to do some Undergraduate Research with) explicitly stated on the first day of class:

*"This is not a java course."*

I don't know about anyone else, but my mind was blown, and this was when I went from being a student who failed to see the cohesion in the material to being an out-and-out scholar who began to look at concepts to try to bring them together into a common channel. It was at this point that I stopped looking at my curriculum as a "string of classes", and instead began to view it as a portfolio of skills that I could apply wherever I went in my life, which ended up turning out to be Graduate School.

I kept this in mind when I chose my electives, and even in my English, History, and Anthropology courses, I connected my technology to the big picture. Like I said in my last blog post, it's not all about the technical contributions - a technical contribution should also have a societal benefit, whether it's making life more efficient, comfortable, or secure. For one, you can see this in a History class that discusses how communication has changed with the advent of radio, television, and the Internet. Students in technical studies need the viewpoint offered by sociological classes to see the impact of their work, and why their degree matters in the first place.

What students don't realize is that their curriculum isn't simply pulled from whim of a disgruntled school administrator looking to make their lives difficult. Curricula are designed around a set of learning objectives that spell out what someone who is holding a degree in a particular field should be able to bring to the table. In theory, this is why an employer can say that you need a B.Sc. in Computer Science to work for them - because they know what having a B.Sc. in Computer Science means thanks to the accredited curriculum that the University follows. Universities work with academics <em>and</em> professionals to put together a curriculum that can teach and assess whether students are capable of living up to the expectations of their degree. Yet students don't think of it that way.

I didn't get to stay long enough to see the end of his talk and hear the big punchline, but I can kind of imagine how it ended. This is the wrong perspective. A college education is more than the sum of its classes, and by giving students a broader view of what they are really doing by taking all of these silly courses might help provide some cohesion so they can take their courses in stride, plan their electives strategically, and end up more prepared than their peers and colleagues. Professors who teach the 100 and 200 level classes are in the best position to do this, because by the time they reach the advanced classes, they're already two years in, and at that point, it might be too late.
